{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sys, os, seaborn, time\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append('../nnBuilder')\n",
    "from nnLayer import *\n",
    "from nnInput import *\n",
    "from nnTrainer import *\n",
    "from nnHandler import *\n",
    "from _nnUtils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "in_size=96\n",
    "out_size=42\n",
    "data=Layer(type=\"Constant\",file='n43w117.npy',convert_file=True,normalize=True)\n",
    "data_test=Layer(type=\"Constant\",file='n43w118.npy',convert_file=True,normalize=True)#Bad test set\n",
    "batch=Layer(x=data,type=\"Pipeline\",batch=128,make_batch=True,\n",
    "            in_features=[dict(type=\"Random_Crop\",shape=[in_size,in_size]),\n",
    "                         dict(type=\"Reshape\",shape=[in_size,in_size,1]),\n",
    "                         dict(type=\"Whitening\"),\n",
    "                        ])\n",
    "batch_test=Layer(x=data_test,type=\"Pipeline\",batch=128,make_batch=True,\n",
    "            in_features=[dict(type=\"Random_Crop\",shape=[in_size,in_size]),\n",
    "                         dict(type=\"Reshape\",shape=[in_size,in_size,1]),\n",
    "                        ])\n",
    "noise=dict(type=\"Noise\",rand_type=\"normal\",scale=0.1,drop_on_test=True)\n",
    "batch_norm=dict(type=\"Batch_Norm\")\n",
    "\n",
    "encoder_layers=[]\n",
    "encoder_layers.append(dict(type=\"Identity_Label\"))\n",
    "encoder_layers.append(dict(type=\"Convolution\",pad=\"VALID\",window=5,stride=1,size=16,relu=True))\n",
    "encoder_layers.append(dict(type=\"Pool\",pad=\"VALID\",window=2,stride=2,pool_type=\"max\"))\n",
    "encoder_layers.append(batch_norm)\n",
    "encoder_layers.append(noise)\n",
    "encoder_layers.append(dict(type=\"Convolution\",pad=\"VALID\",window=5,stride=1,size=32,relu=True))\n",
    "encoder_layers.append(dict(type=\"Pool\",pad=\"VALID\",window=2,stride=2,pool_type=\"max\"))\n",
    "encoder_layers.append(batch_norm)\n",
    "encoder_layers.append(noise)\n",
    "encoder_layers.append(dict(type=\"Convolution\",pad=\"VALID\",window=3,stride=1,size=64,relu=True))\n",
    "encoder_layers.append(batch_norm)\n",
    "encoder_layers.append(noise)\n",
    "encoder_layers.append(dict(type=\"Convolution\",pad=\"VALID\",window=1,stride=1,size=8,relu=False))\n",
    "encoder_layers.append(batch_norm)\n",
    "encoder_def=dict(type=\"Network\",layers=encoder_layers)\n",
    "#encoder=Layer(x=batch,type=\"Network\",layers=encoder_layers)\n",
    "\n",
    "decoder_layers=[]\n",
    "decoder_layers.append(dict(type=\"Convolution\",pad=\"VALID\",window=3,stride=1,size=32,relu=True))\n",
    "encoder_layers.append(batch_norm)\n",
    "decoder_layers.append(dict(type=\"Convolution_Transpose\",pad=\"SAME\",window=5,stride=2,size=64,relu=True))\n",
    "encoder_layers.append(batch_norm)\n",
    "decoder_layers.append(dict(type=\"Convolution_Transpose\",pad=\"SAME\",window=5,stride=2,size=64,relu=True))\n",
    "encoder_layers.append(batch_norm)\n",
    "decoder_layers.append(dict(type=\"Convolution\",pad=\"VALID\",window=3,stride=1,size=1,relu=False))\n",
    "decoder_def=dict(type=\"Network\",layers=decoder_layers)\n",
    "#decoder=Layer(x=encoder,type=\"Network\",layers=decoder_layers)\n",
    "\n",
    "crop_def=dict(type=\"Central_Crop\",shape=[out_size,out_size])\n",
    "crop_def_full=dict(type=\"Network\",layers=[crop_def,dict(type=\"Label\",layer=crop_def)])\n",
    "\n",
    "\n",
    "\n",
    "network=Layer(x=batch,type=\"Network\",layers=[encoder_def,decoder_def,crop_def])\n",
    "network_eval=network.copy(x=batch,test=True,share_vars=True)\n",
    "network_test=network.copy(x=batch_test,test=True,share_vars=True)\n",
    "\n",
    "\n",
    "labels=Layer(x=network.get_labels(),**crop_def)\n",
    "labels_eval=Layer(x=network_eval.get_labels(),**crop_def)\n",
    "labels_test=Layer(x=network_test.get_labels(),**crop_def)\n",
    "\n",
    "trainer=LabeledTrainer(network=network,optimizer=\"adam\",loss=\"mean_squared_error\",labels=labels)\n",
    "tester_eval=LabeledTrainer(network=network_eval,loss=\"mean_squared_error\",test=True,labels=labels_eval)\n",
    "tester=LabeledTrainer(network=network_test,loss=\"mean_squared_error\",test=True,labels=labels_test)\n",
    "\n",
    "\n",
    "sess=SessManager(data,batch,data_test,batch_test,network,network_eval,network_test,trainer,tester_eval,tester)\n",
    "sess.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "batches_per_step=1000#60000//128 #About 1 epoch\n",
    "batches_per_eval=50\n",
    "n_steps=1000\n",
    "def make_plt():\n",
    "    %matplotlib notebook\n",
    "    global fig,ax,train_plot,test_plot,eval_plot\n",
    "    fig,ax = plt.subplots(1,1)\n",
    "    train_plot=ax.plot([],[], label=\"training\")[0]\n",
    "    eval_plot=ax.plot([],[], label=\"eval\")[0]\n",
    "    test_plot=ax.plot([],[], label=\"test\")[0]\n",
    "    ax.set_ylim(0,1)\n",
    "    plt.legend()\n",
    "    fig.canvas.draw()\n",
    "    time.sleep(.01)\n",
    "def update_plt():\n",
    "    x=[batches_per_step*i for i in range(len(trains))]\n",
    "    train_plot.set_xdata(x)\n",
    "    train_plot.set_ydata(trains)\n",
    "    test_plot.set_xdata(x)\n",
    "    test_plot.set_ydata(tests)\n",
    "    eval_plot.set_xdata(x)\n",
    "    eval_plot.set_ydata(evals)\n",
    "    ax.set_xlim(0,x[-1])\n",
    "    ax.set_ylim(0,tests[1]*1.5)\n",
    "    fig.canvas.draw()\n",
    "    #time.sleep(.01)\n",
    "if \"trains\" not in globals():\n",
    "    trains=[trainer.eval_loss(n=batches_per_eval)]\n",
    "    evals=[tester_eval.eval_loss(n=batches_per_eval)]\n",
    "    tests=[tester.eval_loss()]\n",
    "make_plt()\n",
    "for i in range(n_steps):\n",
    "    '''if i>10:\n",
    "        r=1e-5\n",
    "    elif i>5:\n",
    "        r=1e-4\n",
    "    else:'''\n",
    "    r=1e-3\n",
    "    trainer.train(batches_per_step,keep_rate=0.5,l2reg=1e-6,learn_rate=r)\n",
    "    trains.append(trainer.eval_loss(n=batches_per_eval)) #Training error\n",
    "    evals.append(tester_eval.eval_loss(n=batches_per_eval)) \n",
    "    tests.append(tester.eval_loss(n=batches_per_eval))#Testing error\n",
    "    update_plt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a=sess.run(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[a[i].std() for i in range(128)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
