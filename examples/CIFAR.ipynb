{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR-10 classifier from nnBuilder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a simple implementation of a CIFAR-10 classifier using the nnBuilder framework. Trying to reproduce the network of https://www.tensorflow.org/tutorials/deep_cnn/ (Work in progress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('../nnBuilder')\n",
    "from nnLayer import *\n",
    "from nnInput import *\n",
    "from nnTrainer import *\n",
    "from nnHandler import *\n",
    "from _nnUtils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting new session\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.client.session.InteractiveSession at 0xc5e74e0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessing=False #Slow, error rate not lowering?\n",
    "data=Layer(x=None,type=\"CIFAR_10\")\n",
    "preprocess_layers=[]\n",
    "preprocess_layers.append(dict(type=\"Batch_Random_Crop\",shape=[24,24,3]))\n",
    "preprocess_layers.append(dict(type=\"Batch_Random_Horizontal_Flip\"))\n",
    "preprocess_layers.append(dict(type=\"Batch_Random_Brightness\"))\n",
    "preprocess_layers.append(dict(type=\"Batch_Random_Contrast\"))\n",
    "preprocess_layers.append(dict(type=\"Batch_Whitening\"))\n",
    "preprocess_layers.append(dict(type=\"Pipeline\",num_threads=8))\n",
    "batch=Layer(x=data,type=\"Batch_Slice\",batch=128,out_features=preprocessing and preprocess_layers or None)\n",
    "layers=[]\n",
    "layers.append(dict(type=\"Convolution\",pad=\"SAME\",window=5,stride=1,size=64,relu=True,out_features=[\n",
    "              dict(type=\"Pool\",pad=\"SAME\",window=3,stride=2,pool_type=\"max\"),\n",
    "              dict(type=\"Local_Response_Norm\")]))\n",
    "layers.append(dict(type=\"Convolution\",pad=\"SAME\",window=5,stride=1,size=64,relu=True,out_features=[\n",
    "              dict(type=\"Pool\",pad=\"SAME\",window=3,stride=2,pool_type=\"max\"),\n",
    "              dict(type=\"Local_Response_Norm\")]))\n",
    "layers.append(dict(type=\"Relu\",size=384))\n",
    "layers.append(dict(type=\"Relu\",size=192))\n",
    "layers.append(dict(type=\"Linear\",size=10,in_features=[\"Dropout\"]))\n",
    "network_def=dict(type=\"Network\",layers=layers)\n",
    "network=Layer(x=batch,**network_def)\n",
    "trainer=ClassifierTrainer(network=network,optimizer=\"adam\",finish=True)\n",
    "sess=SessManager(data,batch,network,trainer)#,input_network)\n",
    "sess.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate (train): 0.901563\n",
      "Error rate (train): 0.646094\n",
      "Error rate (train): 0.520312\n",
      "Error rate (train): 0.519531\n",
      "Error rate (train): 0.467969\n",
      "Error rate (train): 0.428906\n",
      "Error rate (train): 0.403125\n",
      "Error rate (train): 0.373437\n",
      "Error rate (train): 0.386719\n",
      "Error rate (train): 0.380469\n",
      "Error rate (train): 0.357812\n",
      "Error rate (train): 0.330469\n",
      "Error rate (train): 0.35\n",
      "Error rate (train): 0.339844\n",
      "Error rate (train): 0.301562\n",
      "Error rate (train): 0.317969\n",
      "Error rate (train): 0.290625\n",
      "Error rate (train): 0.285156\n",
      "Error rate (train): 0.246094\n",
      "Error rate (train): 0.275781\n",
      "Error rate (train): 0.251563\n",
      "Error rate (train): 0.278125\n",
      "Error rate (train): 0.282031\n",
      "Error rate (train): 0.220313\n",
      "Error rate (train): 0.252344\n",
      "Error rate (train): 0.228125\n",
      "Error rate (train): 0.225781\n",
      "Error rate (train): 0.222656\n",
      "Error rate (train): 0.235938\n",
      "Error rate (train): 0.2125\n",
      "Error rate (train): 0.19375\n",
      "Error rate (train): 0.220313\n",
      "Error rate (train): 0.2\n",
      "Error rate (train): 0.238281\n",
      "Error rate (train): 0.172656\n",
      "Error rate (train): 0.18125\n",
      "Error rate (train): 0.19375\n",
      "Error rate (train): 0.190625\n",
      "Error rate (train): 0.153906\n",
      "Error rate (train): 0.170312\n",
      "Error rate (train): 0.204688\n",
      "Error rate (train): 0.167187\n",
      "Error rate (train): 0.142969\n",
      "Error rate (train): 0.146875\n",
      "Error rate (train): 0.182031\n",
      "Error rate (train): 0.164063\n",
      "Error rate (train): 0.155469\n",
      "Error rate (train): 0.198437\n",
      "Error rate (train): 0.154687\n",
      "Error rate (train): 0.132813\n",
      "Error rate (train): 0.111719\n"
     ]
    }
   ],
   "source": [
    "trainer.train(0,keep_rate=1.)\n",
    "trainer.eval_error()\n",
    "for i in range(50):\n",
    "    trainer.train(100,keep_rate=1.)\n",
    "    trainer.train(0,keep_rate=1.)\n",
    "    trainer.eval_error() #Training error, reaches about 10% without preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'layers': [{'input_channels': None,\n",
       "   'out_features': [{'pad': 'SAME',\n",
       "     'pool_type': 'max',\n",
       "     'stride': 2,\n",
       "     'type': 'Pool',\n",
       "     'window': 3},\n",
       "    {'type': 'Local_Response_Norm'}],\n",
       "   'pad': 'SAME',\n",
       "   'rand_scale': 0.1,\n",
       "   'relu': True,\n",
       "   'size': 64,\n",
       "   'stride': 1,\n",
       "   'type': 'Convolution',\n",
       "   'window': 5},\n",
       "  {'input_channels': None,\n",
       "   'out_features': [{'pad': 'SAME',\n",
       "     'pool_type': 'max',\n",
       "     'stride': 2,\n",
       "     'type': 'Pool',\n",
       "     'window': 3},\n",
       "    {'type': 'Local_Response_Norm'}],\n",
       "   'pad': 'SAME',\n",
       "   'rand_scale': 0.1,\n",
       "   'relu': True,\n",
       "   'size': 64,\n",
       "   'stride': 1,\n",
       "   'type': 'Convolution',\n",
       "   'window': 5},\n",
       "  {'rand_scale': 0.1, 'size': 384, 'type': 'Relu'},\n",
       "  {'rand_scale': 0.1, 'size': 192, 'type': 'Relu'},\n",
       "  {'in_features': [{'type': 'Dropout'}],\n",
       "   'rand_scale': 0.1,\n",
       "   'size': 10,\n",
       "   'type': 'Linear'}],\n",
       " 'type': 'Network'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.save() #The full network definition\n",
    "save=network.save() #The full network definition\n",
    "assert(Layer(x=batch,**save).save()==save) #Consistency\n",
    "print(save==network_def) #Saving adds stuff, should still be equivalent\n",
    "save"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
